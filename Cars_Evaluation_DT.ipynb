{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data=pd.read_csv(r\"C:\\Python Imarticus\\Basics\\Decision Tree\\cars.csv\",header=None)\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 7)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1728 non-null   object\n",
      " 1   1       1728 non-null   object\n",
      " 2   2       1728 non-null   object\n",
      " 3   3       1728 non-null   object\n",
      " 4   4       1728 non-null   object\n",
      " 5   5       1728 non-null   object\n",
      " 6   6       1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cars_data.shape)\n",
    "print()\n",
    "print(cars_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety classes\n",
       "0  vhigh  vhigh     2       2    small    low   unacc\n",
       "1  vhigh  vhigh     2       2    small    med   unacc\n",
       "2  vhigh  vhigh     2       2    small   high   unacc\n",
       "3  vhigh  vhigh     2       2      med    low   unacc\n",
       "4  vhigh  vhigh     2       2      med    med   unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot','safety', 'classes']\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "classes     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing Values\n",
    "\n",
    "cars_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional to create copy of Df(general practice in industry)\n",
    "\n",
    "cars_df=pd.DataFrame.copy(cars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature buying\n",
      "mapping {'high': 0, 'low': 1, 'med': 2, 'vhigh': 3}\n",
      "Feature maint\n",
      "mapping {'high': 0, 'low': 1, 'med': 2, 'vhigh': 3}\n",
      "Feature doors\n",
      "mapping {'2': 0, '3': 1, '4': 2, '5more': 3}\n",
      "Feature persons\n",
      "mapping {'2': 0, '4': 1, 'more': 2}\n",
      "Feature lug_boot\n",
      "mapping {'big': 0, 'med': 1, 'small': 2}\n",
      "Feature safety\n",
      "mapping {'high': 0, 'low': 1, 'med': 2}\n",
      "Feature classes\n",
      "mapping {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3}\n"
     ]
    }
   ],
   "source": [
    "colname=[]\n",
    "for x in cars_df.columns:\n",
    "    if cars_df[x].dtype=='object':\n",
    "        colname.append(x)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "for x in colname:\n",
    "    cars_df[x]=le.fit_transform(cars_df[x])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print('Feature', x)\n",
    "    print('mapping', le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  classes\n",
       "0       3      3      0        0         2       1        2\n",
       "1       3      3      0        0         2       2        2\n",
       "2       3      3      0        0         2       0        2\n",
       "3       3      3      0        0         1       1        2\n",
       "4       3      3      0        0         1       2        2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1210\n",
       "0     384\n",
       "1      69\n",
       "3      65\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into ind and dep var\n",
    "\n",
    "X=cars_df.values[:,:-1]\n",
    "Y=cars_df.values[:,-1]\n",
    "Y=Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data: Optional here as we have almost we have same range values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model1: Base DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''criterion=gini is the default for decision tree classifier\n",
    "   random_state, lets assume there are 2 vars which have same gini index it selects randomly when we run multiple times \n",
    "               the script later, in oder to select the same var every time random_state is passed'''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "Y_pred=model_DecisionTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   0   1   0]\n",
      " [  2  19   0   0]\n",
      " [  0   0 371   0]\n",
      " [  1   0   0  24]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       102\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.99       519\n",
      "   macro avg       0.99      0.96      0.98       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9922928709055877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('buying', 0.1510848831946676), ('maint', 0.2506508516803624), ('doors', 0.060026331736828115), ('persons', 0.19355707150872045), ('lug_boot', 0.09892620952419463), ('safety', 0.2457546523552268)]\n"
     ]
    }
   ],
   "source": [
    "'''Decision Tree can also be used for feature selection during EDA. Based on the imp of features we select the imp \n",
    "ones and proceed for building model.sum of the importance values of all vars=1, the highest value indicates the most imp var'''\n",
    "\n",
    "print(list(zip(cars_df.columns,model_DecisionTree.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''By above we see doors is the least importance but we didnt get kind of zero value. There will be some datasets where we have \n",
    "multiple vars we get much lower values. We can go ahead and ignore them considering the domain knowledge'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''export_graphviz : exports into text file, the step by step procedure followed while building DT \n",
    "   feature_names: prints the name of the vars, if not used tree is plotted with indices.\n",
    "   \n",
    "   File is generated in the specified directory now upload the code in webgraphviz.com to plot the decision tree'''\n",
    "    \n",
    "from sklearn import tree\n",
    "with open(\"C:\\Python Imarticus\\Basics\\Plots_Reports\\cars_model_DecisionTree.txt\", \"w\") as f:\n",
    "    f = tree.export_graphviz(model_DecisionTree, feature_names=cars_df.columns[:-1],out_file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2: Tuning DT by Pruning Method(Perform this step when necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally above model is performing better on test data. But if we think that this model is overfitted then we prune the tree\n",
    "for tuning the base model. Change in hyperparameters is done for pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''min_samples_leaf: by defualt is 1 which means every leaf has 1 obs which means it is overfiited, to avoid this we give min \n",
    "                     no of obs\n",
    "   max_depth: total levels of the tree,ideally it grows to full levels, to aviod we give certain no(generally 2/3rd of the \n",
    "            base model value-model_DecisionTree.get_depth()) after which there is no further splitting'''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion='gini',min_samples_leaf=5,max_depth=10,random_state=10)\n",
    "model_DecisionTree.fit(X_train,Y_train)\n",
    "Y_pred=model_DecisionTree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92   6   4   0]\n",
      " [  0  17   2   2]\n",
      " [  8   0 363   0]\n",
      " [  3   5   0  17]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       102\n",
      "           1       0.61      0.81      0.69        21\n",
      "           2       0.98      0.98      0.98       371\n",
      "           3       0.89      0.68      0.77        25\n",
      "\n",
      "    accuracy                           0.94       519\n",
      "   macro avg       0.84      0.84      0.84       519\n",
      "weighted avg       0.95      0.94      0.94       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9421965317919075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Pruned DT\n",
    "\n",
    "from sklearn import tree\n",
    "with open(\"C:\\Python Imarticus\\Basics\\Plots_Reports\\cars_pruned_model_DecisionTree.txt\", \"w\") as f:\n",
    "    f = tree.export_graphviz(model_DecisionTree, feature_names=cars_df.columns[:-1],out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''By above we see lower accuracy. Original model was doing good job. This shows we shouldn't do unnecessary Pruning.\n",
    " When we see the plot we see that there are some leaf nodes where we have same samples in multiple classes. Due to random\n",
    " selection it might have wrongly predicted due to which accuracy drops'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cross Validation-Comparing Logistic,KNN,SVM algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier=svm.SVC(kernel=\"rbf\", gamma=0.1, C=1)\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82   0  20   0]\n",
      " [ 21   0   0   0]\n",
      " [ 17   0 354   0]\n",
      " [ 17   0   0   8]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69       102\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.95      0.95      0.95       371\n",
      "           3       1.00      0.32      0.48        25\n",
      "\n",
      "    accuracy                           0.86       519\n",
      "   macro avg       0.64      0.52      0.53       519\n",
      "weighted avg       0.84      0.86      0.84       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.8554913294797688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neeharika\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier=svm.SVC(kernel=\"rbf\", gamma=0.1, C=50)\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   1   1   0]\n",
      " [  0  21   0   0]\n",
      " [  0   0 371   0]\n",
      " [  0   0   0  25]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       102\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       519\n",
      "   macro avg       0.99      1.00      0.99       519\n",
      "weighted avg       1.00      1.00      1.00       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9961464354527938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_KNN=KNeighborsClassifier(n_neighbors=8,metric='euclidean')\n",
    "model_KNN.fit(X_train,Y_train)\n",
    "Y_pred=model_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97   1   4   0]\n",
      " [  8  12   0   1]\n",
      " [ 10   0 361   0]\n",
      " [  3   0   0  22]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       102\n",
      "           1       0.92      0.57      0.71        21\n",
      "           2       0.99      0.97      0.98       371\n",
      "           3       0.96      0.88      0.92        25\n",
      "\n",
      "    accuracy                           0.95       519\n",
      "   macro avg       0.92      0.84      0.87       519\n",
      "weighted avg       0.95      0.95      0.95       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9479768786127167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neeharika\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Neeharika\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   0  80   0]\n",
      " [  3   0  18   0]\n",
      " [ 30   0 341   0]\n",
      " [ 11   0  14   0]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.26       102\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.75      0.92      0.83       371\n",
      "           3       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.70       519\n",
      "   macro avg       0.27      0.28      0.27       519\n",
      "weighted avg       0.60      0.70      0.64       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.6994219653179191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neeharika\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''By above cross validation we observe that Tuned SVM has given highest accuracy followed by Base DT and KNN. Logistic is \n",
    "not suitable for multiclass predictions. We can take a call among Tuned SVM and Base DT considering complexity and accuracy \n",
    "of algorithms. Ideally for tuned SVM we need to do trail and error(for changing hyper parameters-refer SVM code file) \n",
    "which leads to complexity due to tuning. Regularizationand penalisation cost incur. Hence if we need to choose b/w two \n",
    "we go for simple base DT than complex Tuned SVM'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
