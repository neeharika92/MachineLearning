{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data=pd.read_csv(r\"C:\\Python Imarticus\\Basics\\Decision Tree\\cars.csv\",header=None)\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 7)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1728 non-null   object\n",
      " 1   1       1728 non-null   object\n",
      " 2   2       1728 non-null   object\n",
      " 3   3       1728 non-null   object\n",
      " 4   4       1728 non-null   object\n",
      " 5   5       1728 non-null   object\n",
      " 6   6       1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cars_data.shape)\n",
    "print()\n",
    "print(cars_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety classes\n",
       "0  vhigh  vhigh     2       2    small    low   unacc\n",
       "1  vhigh  vhigh     2       2    small    med   unacc\n",
       "2  vhigh  vhigh     2       2    small   high   unacc\n",
       "3  vhigh  vhigh     2       2      med    low   unacc\n",
       "4  vhigh  vhigh     2       2      med    med   unacc"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot','safety', 'classes']\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "classes     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Missing Values\n",
    "\n",
    "cars_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional to create copy of Df(general practice in industry)\n",
    "\n",
    "cars_df=pd.DataFrame.copy(cars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature buying\n",
      "mapping {'high': 0, 'low': 1, 'med': 2, 'vhigh': 3}\n",
      "Feature maint\n",
      "mapping {'high': 0, 'low': 1, 'med': 2, 'vhigh': 3}\n",
      "Feature doors\n",
      "mapping {'2': 0, '3': 1, '4': 2, '5more': 3}\n",
      "Feature persons\n",
      "mapping {'2': 0, '4': 1, 'more': 2}\n",
      "Feature lug_boot\n",
      "mapping {'big': 0, 'med': 1, 'small': 2}\n",
      "Feature safety\n",
      "mapping {'high': 0, 'low': 1, 'med': 2}\n",
      "Feature classes\n",
      "mapping {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3}\n"
     ]
    }
   ],
   "source": [
    "colname=[]\n",
    "for x in cars_df.columns:\n",
    "    if cars_df[x].dtype=='object':\n",
    "        colname.append(x)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "for x in colname:\n",
    "    cars_df[x]=le.fit_transform(cars_df[x])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print('Feature', x)\n",
    "    print('mapping', le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  classes\n",
       "0       3      3      0        0         2       1        2\n",
       "1       3      3      0        0         2       2        2\n",
       "2       3      3      0        0         2       0        2\n",
       "3       3      3      0        0         1       1        2\n",
       "4       3      3      0        0         1       2        2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1210\n",
       "0     384\n",
       "1      69\n",
       "3      65\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into ind and dep var\n",
    "\n",
    "X=cars_df.values[:,:-1]\n",
    "Y=cars_df.values[:,-1]\n",
    "Y=Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data: Optional here as we have almost we have same range values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1: Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model=ExtraTreesClassifier(n_estimators=10,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95   2   5   0]\n",
      " [  2  19   0   0]\n",
      " [ 17   0 354   0]\n",
      " [  2   1   0  22]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       102\n",
      "           1       0.86      0.90      0.88        21\n",
      "           2       0.99      0.95      0.97       371\n",
      "           3       1.00      0.88      0.94        25\n",
      "\n",
      "    accuracy                           0.94       519\n",
      "   macro avg       0.92      0.92      0.92       519\n",
      "weighted avg       0.95      0.94      0.95       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9441233140655106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''N_estimators=10 is default, where we got above accuracy. To increase it we can change the n value and see for better \n",
    "accuracy. Also the hyper parameters we used for pruining for DT can also be used here for pruning.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change n value \n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model=ExtraTreesClassifier(n_estimators=100,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   1   0   0]\n",
      " [  3  18   0   0]\n",
      " [  1   0 370   0]\n",
      " [  1   2   0  22]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       102\n",
      "           1       0.86      0.86      0.86        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.88      0.94        25\n",
      "\n",
      "    accuracy                           0.98       519\n",
      "   macro avg       0.95      0.93      0.94       519\n",
      "weighted avg       0.98      0.98      0.98       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9845857418111753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=10,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   3   1   0]\n",
      " [  3  17   0   1]\n",
      " [  2   0 369   0]\n",
      " [  5   2   0  18]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       102\n",
      "           1       0.77      0.81      0.79        21\n",
      "           2       1.00      0.99      1.00       371\n",
      "           3       0.95      0.72      0.82        25\n",
      "\n",
      "    accuracy                           0.97       519\n",
      "   macro avg       0.91      0.87      0.88       519\n",
      "weighted avg       0.97      0.97      0.97       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9672447013487476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''N_estimators=10 is default, where we got above accuracy. To increase it we can change the n value and see for better \n",
    "accuracy. Also the hyper parameters we used for pruining for DT can also be used here for pruning.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change n value \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=1000,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99   3   0   0]\n",
      " [  1  19   0   1]\n",
      " [  2   0 369   0]\n",
      " [  1   0   0  24]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       102\n",
      "           1       0.86      0.90      0.88        21\n",
      "           2       1.00      0.99      1.00       371\n",
      "           3       0.96      0.96      0.96        25\n",
      "\n",
      "    accuracy                           0.98       519\n",
      "   macro avg       0.95      0.96      0.95       519\n",
      "weighted avg       0.98      0.98      0.98       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9845857418111753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For both extra trees and random forest algorithms, we are getting lower than base model of DT. This is so due to \n",
    "the majority voting may be randomly classes are selected and miss classfications due to which accuracy dropped. \n",
    "Hence we go back to base DT. Where base DT doesn't perform well this ensemble model may give better results'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1: AdaBoost Classfier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We can give the hyper parameters related to decision tree DecisionTreeClassifier(random_state=10,criterion etc)'''\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_AdaBoost=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=10),n_estimators=10,random_state=10)\n",
    "model_AdaBoost.fit(X_train,Y_train)\n",
    "Y_pred=model_AdaBoost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99   2   1   0]\n",
      " [  4  17   0   0]\n",
      " [  0   0 371   0]\n",
      " [  1   0   0  24]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       102\n",
      "           1       0.89      0.81      0.85        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98       519\n",
      "   macro avg       0.96      0.94      0.95       519\n",
      "weighted avg       0.98      0.98      0.98       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9845857418111753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2: GradientBoosting Classfier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model=GradientBoostingClassifier(n_estimators=150,random_state=10)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   1   0   0]\n",
      " [  0  21   0   0]\n",
      " [  0   0 371   0]\n",
      " [  0   0   0  25]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       102\n",
      "           1       0.95      1.00      0.98        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00       519\n",
      "   macro avg       0.99      1.00      0.99       519\n",
      "weighted avg       1.00      1.00      1.00       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9980732177263969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''By Above Boosting techniques we see that Gradient Boosting is giving better results than base DT. This is generally \n",
    "one of the tuning techniques of DT. Ideally these ensembling techniques are complex and expensive, hence in industry\n",
    "we generally go for base DT than these techniques'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neeharika\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Neeharika\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('log', model1))\n",
    "model2 = DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC(kernel=\"rbf\", C=50,gamma=0.1)\n",
    "estimators.append(('svm', model3))\n",
    "model4 = KNeighborsClassifier(n_neighbors=8, metric='euclidean')\n",
    "estimators.append(('knn', model4))\n",
    "\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train,Y_train)\n",
    "Y_pred=ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   1   0   0]\n",
      " [  4  17   0   0]\n",
      " [  2   0 369   0]\n",
      " [  2   0   0  23]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       102\n",
      "           1       0.94      0.81      0.87        21\n",
      "           2       1.00      0.99      1.00       371\n",
      "           3       1.00      0.92      0.96        25\n",
      "\n",
      "    accuracy                           0.98       519\n",
      "   macro avg       0.97      0.93      0.95       519\n",
      "weighted avg       0.98      0.98      0.98       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9826589595375722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''As we know this is multi class, we remove logistic and go further'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model2 = DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC(kernel=\"rbf\", C=50,gamma=0.1)\n",
    "estimators.append(('svm', model3))\n",
    "model4 = KNeighborsClassifier(n_neighbors=8, metric='euclidean')\n",
    "estimators.append(('knn', model4))\n",
    "\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train,Y_train)\n",
    "Y_pred=ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   1   0   0]\n",
      " [  2  19   0   0]\n",
      " [  0   0 371   0]\n",
      " [  1   0   0  24]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       102\n",
      "           1       0.95      0.90      0.93        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.99       519\n",
      "   macro avg       0.98      0.96      0.97       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9922928709055877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''By individual model accuracies we saw that tuned SVM and base DT are good. Hence we go and build taking only these models'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model2 = DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC(kernel=\"rbf\", C=50,gamma=0.1)\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train,Y_train)\n",
    "Y_pred=ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   0   0   0]\n",
      " [  2  19   0   0]\n",
      " [  0   0 371   0]\n",
      " [  1   0   0  24]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.99       519\n",
      "   macro avg       0.99      0.97      0.98       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n",
      "\n",
      "Accuracy of the model:  0.9942196531791907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "acc=accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
